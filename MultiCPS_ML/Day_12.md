## **다중회귀분석(변수선택)**

### 다중회쉬모형의 변수선택 개요

- 가능한 적은 수의 설명변수로 좋은 예측력을 가지는 모형을 찾고자 함
- 변수선택법
    - 전진선택법(forward selection)
    - 후진제거법(backward elimination)
    - 단계선택법(stepwise method)
    - 모든 가능한 조합의 회귀분석 : 모든 가능한 독립변수들의 조합에 대한 회귀모형을 생성한 뒤 가장 적합한 회귀모형을 선택
    

### 변수 선택 방법

- 전진선택법(forward selection)
    - 절편만 있는 모델에서 출발하여 중요한 변수를 하나씩 추가하는 방식
    - 한 번 선택된 변수는 제거되지 않는 단점이 있음
        - 어떤 변수가 추가됨으로 인해 기존의 모형이 의미를 상실하게 되는 경우 존재
    - 더 이상 추가할 변수가 없으면 Stop
        - 검정을 통해 변수 추가를 확인
        - 귀무가설은 $\beta_j$가 0(축소 모형), 대립가설은 not 0(완전 모형)
        - 부분 F 검정 사용 → 완전모형에서 일부에 대한 제약을 가하고 제약이 유효한지를 판단
- 후진제거법(backward elimination)
    - 모든 변수가 포함된 모델에서 가장 중요하지 않은 변수부터 하나씩 제거
    - 한 번 제거된 변수는 선택되지 않는 단점이 있음
- 단계선택법(stepwise method)
    - 절편만 포함된 모델에서 출발해 가장 중요한 변수부터 추가하고 모델에 포함되어 있는 변수 중에서 중요하지 않은 변수를 제거함
        - 기존의 모델에서 변수가 제거되는 경우는 추가되는 변수와 비교시 correlation이 높은 경우, 즉 의미가 중복되는 경우 제거되기 쉽다.
    - 더 이상 새롭게 추가되는 변수가 없을 때까지 변수의 추가 또는 삭제를 반복함.

### 모형선택의 기준

- 수정된 결정계수(Adjusted $R^2$) : 클수록 좋다
    - 결정계수 $R^2$는 새로운 독립변수가 추가되면 항상 증가한다.
        - SSE가 최소가 되는 방향으로 학습을 한다. : 모형으로 설명할 수 없는 변동 줄이기.
        → SSE는 변수 하나라도 추가되면 감소한다
        → $SSE = \sum (y_i - \hat y_i)^2 = \sum (y_i - \hat \alpha - \hat \beta_1 x_{1i})^2 \ge \sum (y_i - \hat \alpha - \hat \beta_1 x_{1i} - \hat \beta_2 x_{2i})^2$
        → $SST$는  $y_i$와 $\bar y_i$의 식이기에 영향을 안받는다.
        → $1- \dfrac {SSE} {SST}$은 증가한다.
    - 이를 보완한 수정결정계수 Adjusted $R^2$는 **추가된 독립변수가 종속변수를 설명하는데 기여하는 바가 큰 경우에만 증가**함
    $Adjusted R^2 = 1 - \dfrac {SSE/(n-k-1)} {SST/(n-1)}$ : 자유도로 나눴다. k = 독립변수의 개수
        - $SSE/(n-k-1)$ 가 줄어드는 경우는 독립변수를 추가해 분모가 줄어드는 양보다 SSE가 줄어드는 폭이 클 때 감소한다.
    - 그 밖에 AIC, BIC, Mallow’s Cp 등의 다양한 적합도 지표를 이용할 수 있음
        - 작을수록 좋다
